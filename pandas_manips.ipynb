{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from multiprocessing import Pool\n",
    "from scipy.linalg import qr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from fastcluster import linkage\n",
    "from scipy.cluster.hierarchy import fcluster, leaves_list, optimal_leaf_ordering\n",
    "from collections import Counter\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-mounting",
   "metadata": {},
   "source": [
    "# Generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_stack(frame, to_stack, new_names):\n",
    "    assert set(to_stack) < set(frame)\n",
    "    assert isinstance(new_names, list) and len(new_names) == 2\n",
    "    cols = frame.columns\n",
    "    index = list(cols[~cols.isin(to_stack)])\n",
    "    frame = frame.set_index(index).stack().reset_index()\n",
    "    frame.columns = index + new_names\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-northern",
   "metadata": {},
   "source": [
    "# Load data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_close_prices(tickers):\n",
    "#     prices are not adjusted for splits or dividends\n",
    "    history = {\n",
    "        tic: yf.Ticker(tic).history(period='max')\n",
    "        for tic in tickers}\n",
    "    indexes = [set(data.index) for data in history.values()]\n",
    "    index = sorted(set.union(*indexes))\n",
    "    closes = pd.concat([\n",
    "        history[tic].reindex(index=index)['Close'].ffill()\n",
    "        for tic in tickers], axis=1)\n",
    "    closes.columns = tickers\n",
    "    stacked = closes.stack().reset_index()\n",
    "    stacked.columns = ['date', 'ticker', 'price']\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tickers = ['msft', 'aapl', 'goog']\n",
    "closes = load_close_prices(tickers)\n",
    "closes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-contributor",
   "metadata": {},
   "source": [
    "# Signal preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_membership(xs_len, mean_prop):\n",
    "    dates = pd.bdate_range('2010', '2020')\n",
    "    membership = np.random.rand(len(dates), xs_len) < mean_prop\n",
    "    return pd.DataFrame(index=dates, data=membership)\n",
    "\n",
    "def gen_data(membership):\n",
    "    data = np.random.randn(*membership.shape)\n",
    "    return (\n",
    "        pd.DataFrame(index=membership.index, data=data)\n",
    "        .where(membership))\n",
    "\n",
    "def plot_desc(descs, **plot_pars):\n",
    "    cols = descs.columns\n",
    "    quantiles = list(cols[~cols.isin(['count', 'mean', 'std'])])\n",
    "    for cols in [\n",
    "        {'count'} & set(cols),\n",
    "        sorted({'mean', 'std'} & set(cols)),\n",
    "        quantiles]:\n",
    "        plt.figure()\n",
    "        descs.loc[:, cols].plot(grid=True, **plot_pars)\n",
    "        plt.show()\n",
    "\n",
    "def plot_desc_pfo_matrix(weights, percentiles=None, **plot_pars):\n",
    "    descs = weights.T.describe(percentiles).T\n",
    "    plot_desc(descs, **plot_pars)\n",
    "\n",
    "def standard_scaler(weights):\n",
    "    means = weights.mean(axis=1)\n",
    "    stds = weights.std(axis=1)\n",
    "    return weights.sub(means, axis=0).div(stds, axis=0)\n",
    "\n",
    "def min_diff(line):\n",
    "    diffs = line.sort_values().diff()\n",
    "    return diffs[diffs > 0].min()\n",
    "\n",
    "def perturbation_with_ranks_preserved_if_different(weights, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    random_signs = np.sign(rng.uniform(-1, 1, weights.shape))  # a.s. != 0\n",
    "    min_diffs = weights.apply(min_diff, axis=1)\n",
    "    random_signs = pd.DataFrame(data=random_signs, index=weights.index, columns=weights.columns)\n",
    "    return weights + random_signs.mul(0.4 * min_diffs, axis=0)  # < 0.5\n",
    "\n",
    "def ranks_uniform_transformer(weights, abso=True, break_ties=False, seed=0):\n",
    "    # Random seed `seed` is used to break ties (if break_ties=True)\n",
    "    if break_ties:\n",
    "        weights = perturbation_with_ranks_preserved_if_different(weights, seed)\n",
    "    ranks = weights.rank(axis=1)\n",
    "    means = ranks.mean(axis=1)\n",
    "    beta = (\n",
    "        ranks\n",
    "        .agg(['min', 'max'], axis=1)\n",
    "        .sub(means, axis=0)\n",
    "        .abs()\n",
    "        .max(axis=1)\n",
    "        .rdiv(1))\n",
    "    unif = ranks.mul(beta, axis=0).add(-beta * means, axis=0)\n",
    "    if not abso:\n",
    "        unif = unif.add(1).div(2)\n",
    "    return unif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-pencil",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IND = 150\n",
    "membership = gen_membership(5000, 0.5)\n",
    "\n",
    "weights = gen_data(membership)\n",
    "betas = gen_data(membership)\n",
    "plot_desc_pfo_matrix(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of perturbation_ranks_preserved_if_different\n",
    "weights_noised = perturbation_with_ranks_preserved_if_different(weights)\n",
    "ranks = weights.rank(axis=1)\n",
    "ranks_noised = weights_noised.rank(axis=1)\n",
    "are_equal_ranks = (ranks != ranks_noised).where(membership)\n",
    "are_equal_ranks.sum(axis=1).plot(grid=True)\n",
    "(ranks.fillna(0) != ranks_noised.fillna(0)).sum().sum(), (weights == weights_noised).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized = standard_scaler(weights)\n",
    "plot_desc_pfo_matrix(standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.iloc[IND].hist(bins=100, alpha=0.3)\n",
    "standardized.iloc[IND].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-pitch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniformized = ranks_uniform_transformer(weights)\n",
    "plot_desc_pfo_matrix(uniformized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.iloc[IND].hist(bins=100, alpha=0.3)\n",
    "uniformized.iloc[IND].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-complex",
   "metadata": {},
   "source": [
    "# Neutralize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-violation",
   "metadata": {},
   "source": [
    "## Utils and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_line(inner_prod, vec, unit_dir_vec):\n",
    "    return inner_prod(vec, unit_dir_vec) * unit_dir_vec\n",
    "\n",
    "def normalize(inner_prod, vec):\n",
    "    return vec * inner_prod(vec, vec) ** -.5\n",
    "\n",
    "def proj_orthonormal_basis(inner_prod, vec, orthon_basis):\n",
    "    return vec - sum([proj_line(inner_prod, vec, vec_dir) for vec_dir in orthon_basis])\n",
    "\n",
    "def canonical_orthonormalize(vecs):\n",
    "    basis = qr(np.array(vecs).T, mode='economic')[0]\n",
    "    return list(basis.T)\n",
    "\n",
    "def gram_schmidt_process(inner_prod, vecs):\n",
    "    append_one = lambda vecs_so_far, vec: vecs_so_far + [normalize(\n",
    "        inner_prod, proj_orthonormal_basis(inner_prod, vec, vecs_so_far))]\n",
    "    return reduce(append_one, vecs, [])\n",
    "\n",
    "def ortho_proj(inner_prod, vec, vecs):\n",
    "    process = (\n",
    "        canonical_orthonormalize if inner_prod.__name__ == 'dot' else\n",
    "        lambda x: gram_schmidt_process(inner_prod, x))\n",
    "    orthon_basis = process(vecs)\n",
    "#     orthon_basis = gram_schmidt_process(inner_prod, vecs)\n",
    "    return proj_orthonormal_basis(inner_prod, vec, orthon_basis)\n",
    "\n",
    "def gram_matrix(inner_prod, vecs):\n",
    "    return np.array([[inner_prod(vec_1, vec_2) for vec_1 in vecs] for vec_2 in vecs])\n",
    "\n",
    "def proj_hyperplane(inner_prod, vec, or_vec):\n",
    "    basis = [normalize(inner_prod, or_vec)]\n",
    "    return proj_orthonormal_basis(inner_prod, vec, basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-distinction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "inn = np.dot\n",
    "vec = np.random.randn(10)\n",
    "unit_vec = normalize(inn, vec)\n",
    "np.linalg.norm(unit_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = proj_line(inn, vec, unit_vec)\n",
    "np.abs(inn(proj, unit_vec)), np.linalg.norm(proj) * np.linalg.norm(unit_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = [np.random.randn(10) for _ in range(3)]\n",
    "orthon_basis = canonical_orthonormalize(vecs)\n",
    "gram_matrix(inn, orthon_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = proj_orthonormal_basis(inn, vec, orthon_basis)\n",
    "[inn(proj, vec_) for vec_ in orthon_basis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "orthon_basis_2 = gram_schmidt_process(inn, vecs)\n",
    "gram_matrix(inn, orthon_basis_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "[vec_1 - vec_2 for vec_1, vec_2 in zip(orthon_basis, orthon_basis_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_2 = proj_orthonormal_basis(inn, vec, orthon_basis_2)\n",
    "[inn(proj_2, vec_) for vec_ in orthon_basis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj - proj_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_3 = ortho_proj(inn, vec, vecs)\n",
    "proj_3 - proj_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "inn = lambda x, y: np.cov(x, y)[0][1]\n",
    "vec = np.random.randn(10)\n",
    "unit_vec = normalize(inn, vec)\n",
    "np.linalg.norm(unit_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = proj_line(inn, vec, unit_vec)\n",
    "np.abs(inn(proj, unit_vec)), np.linalg.norm(proj) * np.linalg.norm(unit_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = [np.random.randn(10) for _ in range(3)]\n",
    "orthon_basis = canonical_orthonormalize(vecs)\n",
    "gram_matrix(inn, orthon_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = proj_orthonormal_basis(inn, vec, orthon_basis)\n",
    "[inn(proj, vec_) for vec_ in orthon_basis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "orthon_basis_2 = gram_schmidt_process(inn, vecs)\n",
    "gram_matrix(inn, orthon_basis_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "[vec_1 - vec_2 for vec_1, vec_2 in zip(orthon_basis, orthon_basis_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_2 = proj_orthonormal_basis(inn, vec, orthon_basis_2)\n",
    "[inn(proj_2, vec_) for vec_ in orthon_basis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj - proj_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_3 = ortho_proj(inn, vec, vecs)\n",
    "proj_3 - proj_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-omaha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_vec = np.random.randn(10)\n",
    "proj = proj_hyperplane(inn, vec, or_vec)\n",
    "inn(proj, or_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-orleans",
   "metadata": {},
   "source": [
    "## Neutralizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize(inn, weights, betas, membership):\n",
    "    weights_t = weights.where(membership).fillna(0).T\n",
    "    betas_t = betas.where(membership).fillna(0).T\n",
    "    return (\n",
    "        weights_t.combine(betas_t, lambda x, y: proj_hyperplane(inn, x, y))\n",
    "        .T.where(membership))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutralized_standardized = neutralize(np.dot, standardized, betas, membership)\n",
    "neutralized_uniformized = neutralize(np.dot, uniformized, betas, membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.mul(betas).sum(axis=1).plot()\n",
    "neutralized_standardized.mul(betas).sum(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-december",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_desc_pfo_matrix(neutralized_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.iloc[IND].hist(bins=100, alpha=0.3)\n",
    "neutralized_standardized.iloc[IND].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniformized.mul(betas).sum(axis=1).plot()\n",
    "neutralized_uniformized.mul(betas).sum(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_desc_pfo_matrix(neutralized_uniformized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniformized.iloc[IND].hist(bins=100, alpha=0.3)\n",
    "neutralized_uniformized.iloc[IND].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-andrews",
   "metadata": {},
   "source": [
    "## Neutralizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize_multi(select_date, membership):\n",
    "    with Pool() as pool:\n",
    "        residuals = dict(pool.imap_unordered(select_date, membership.index))\n",
    "    return (\n",
    "        pd.DataFrame(residuals)\n",
    "        .T\n",
    "        .where(membership)\n",
    "        .sort_index()\n",
    "        )\n",
    "\n",
    "factors = [gen_data(membership) for _ in range(5)]\n",
    "kwargs = {\n",
    "    'weights_0': standardized.where(membership).fillna(0),\n",
    "    'factors_0': [factor.where(membership).fillna(0) for factor in factors],\n",
    "    'inn': lambda x, y: np.cov(x, y)[0][1],\n",
    "    # inn = lambda x, y: np.ma.cov(np.ma.masked_invalid(x), np.ma.masked_invalid(y))[0][1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def select_date(date):\n",
    "    wei = kwargs['weights_0'].loc[date, :]\n",
    "    facs = [factor.loc[date, :] for factor in kwargs['factors_0']]\n",
    "    return date, ortho_proj(kwargs['inn'], wei, facs)\n",
    "\n",
    "neutralized_standardized = neutralize_multi(select_date, membership)\n",
    "\n",
    "kwargs['weights_0'] = uniformized.where(membership).fillna(0)\n",
    "neutralized_uniformized = neutralize_multi(select_date, membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corrs_neutralized_standardized = pd.concat([\n",
    "    neutralized_standardized.corrwith(factor, axis=1) for factor in factors],\n",
    "    axis=1)\n",
    "corrs_neutralized_standardized.plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_desc_pfo_matrix(neutralized_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.iloc[IND].hist(bins=100, alpha=0.3)\n",
    "neutralized_standardized.iloc[IND].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corrs_neutralized_uniformized = pd.concat([\n",
    "    neutralized_uniformized.corrwith(factor, axis=1) for factor in factors],\n",
    "    axis=1)\n",
    "corrs_neutralized_uniformized.plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_desc_pfo_matrix(neutralized_uniformized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniformized.iloc[IND].hist(bins=100, alpha=0.3)\n",
    "neutralized_uniformized.iloc[IND].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-dynamics",
   "metadata": {},
   "source": [
    "# Clustering correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://gmarti.gitlab.io/qfin/2020/03/22/herc-part-i-implementation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_corr(corr_df):\n",
    "    names = np.array(list(corr_df))\n",
    "    corr = corr_df.values\n",
    "    dissimilarities = 1 - corr\n",
    "    condensed = dissimilarities[np.triu_indices(len(corr_df), k=1)]\n",
    "    link = linkage(condensed, method='ward')\n",
    "    perm = leaves_list(optimal_leaf_ordering(link, condensed))\n",
    "    sorted_corr_df = pd.DataFrame(\n",
    "        index=names[perm], columns=names[perm], data=corr[perm, :][:, perm])\n",
    "    return link, perm, sorted_corr_df\n",
    "\n",
    "def cut_linkage(link, n_clusters):\n",
    "    c_inds = fcluster(link, n_clusters, criterion='maxclust')\n",
    "    return sorted(Counter(c_inds).items(), key=lambda x: x[0])\n",
    "\n",
    "def plot_clusters(sorted_corr_df, clusters_sizes):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pcolormesh(sorted_corr_df)\n",
    "#     sns.heatmap(sorted_corr_df)  # import seaborn as sns\n",
    "    sizes = np.cumsum([0] + [y for _, y in clusters_sizes])\n",
    "    dim = len(sorted_corr_df)\n",
    "    for left, right in zip(sizes, sizes[1:]):\n",
    "        plt.axvline(x=left, ymin=left / dim, ymax=right / dim, color='r')\n",
    "        plt.axvline(x=right, ymin=left / dim, ymax=right / dim, color='r')\n",
    "        plt.axhline(y=left, xmin=left / dim, xmax=right / dim, color='r')\n",
    "        plt.axhline(y=right, xmin=left / dim, xmax=right / dim, color='r')\n",
    "    cols = iter(list(sorted_corr_df))\n",
    "    print([list(islice(cols, n_eles)) for _, n_eles in clusters_sizes])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "yf_tickers = [\n",
    "    'nio', 'dwac', 'edu', 'didi', 'gme', 'aapl', 'tsla', 'amc', 'pg', 'f', 'snap', 'amzn',\n",
    "    'dis', 'msft', 'ge', 'rivn', 'bros', 'goog', 'googl', 'ccl', 'amd', 'nvda']\n",
    "rets = (\n",
    "    load_close_prices(yf_tickers)\n",
    "    .pivot(index='date', columns='ticker', values='price')\n",
    "    .pct_change()\n",
    "#     .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corr_df = rets.fillna(0).corr()  # TODO: handle nan more properly...\n",
    "link, perm, sorted_corr_df = sort_corr(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_clusters = 6\n",
    "sizes = cut_linkage(link, n_clusters)\n",
    "plot_clusters(sorted_corr_df, sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
